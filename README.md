# Pytorch Gradient Consistency Loss
A PyTorch implementation of the gradient consistency loss function, based on:

Penney, G.P., et al.: A comparison of similarity measures for use in 2-D-3-D medical image registration. _IEEE transactions on medical imaging 17(4)_ (1998) 586â€“595 

and 

Hiasa Y, Otake Y, Takao M, et al. Cross-modality image synthesis from unpaired data using CycleGAN. _Springer_; 2018:31-41.


****************************************************************************************************************************

The gradient consistency loss is an implementation of the gradient correlation (GC), which is defined by the normalized cross correlation (NCC) between the gradients of two images. Given two images, A and B, the GC is defined as

<img src="https://render.githubusercontent.com/render/math?math=GC(A,B) = \frac{1}{2}\{ NCC(\triangledown_{x}A, \triangledown_{x}B\right) + NCC(\triangledown_{y}A, \triangledown_{y}B)\">

where \( \triangledown_{x}\) and \( \triangledown_{y}\) are the gradient operators in the horizontal and vertical directions, respectively. The \( NCC(A,B)\) is defined as 

<img src="https://render.githubusercontent.com/render/math?math=NCC\left(A,B\right) = \frac{\sum_{(i,j)}^{}(A -\overline{A})(B -\overline{B})}{\sqrt{\sum_{(i,j)}^{}(A -\overline{A})^{2}}\sqrt{\sum_{(i,j)}^{}(B -\overline{B})^{2}}}">

where \(\overline{A}\) and \(\overline{B}\)represent the mean values of \(A\) and \(B\), respectively. Using these equations, the gradient consistency loss \( L_{GC}\) can be defined as

<img src="https://render.githubusercontent.com/render/math?math=L_{GC}\left(G\right) = \mathbb{E}_{x,y,z}[1 - GC\left(y,G\left(x,z\right)\right)]">

where \( G\) is the generative model, \( x\) is the input image, \( z\) is a random noise vector, and \( y\) is the target image. By combing this loss function with the adversarial loss (1) and L1 loss (2), the complete objective function is defined as 

<img src="https://render.githubusercontent.com/render/math?math=G^{\ast } = arg\min_{G}\max_{D} L_{adv} + \lambda_{L1} L_{L1} + \lambda_{GC} L_{GC}">
